{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler 已保存到 C:\\Users\\27535\\Desktop\\大数据挑战赛\\model\\scaler.bin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# ========== 工具函数 ==========\n",
    "def inputdata(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, header=0, sep=\",\", encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, header=0, sep=\",\", encoding=\"gbk\")\n",
    "\n",
    "def outputdata(path, data, is_index=False):\n",
    "    data.to_csv(path, index=is_index, header=True, sep=\",\", mode=\"w\", encoding=\"utf-8\")\n",
    "\n",
    "def transcolname(df, column_mapping):\n",
    "    return df.rename(columns=column_mapping)\n",
    "\n",
    "def trans_datetime(df):\n",
    "    df['Date_str'] = df['Date']\n",
    "    dt = pd.to_datetime(df['Date_str'], format='%Y-%m-%d')\n",
    "\n",
    "    df['year'] = dt.dt.year\n",
    "    df['month'] = dt.dt.month\n",
    "    df['day'] = dt.dt.day\n",
    "    df['weekday'] = dt.dt.weekday\n",
    "\n",
    "    unique_dates = pd.Series(dt.dt.strftime('%Y-%m-%d')).sort_values().unique()\n",
    "    date_mapping = {date: i + 1 for i, date in enumerate(unique_dates)}\n",
    "    df['Date'] = dt.dt.strftime('%Y-%m-%d').map(date_mapping)\n",
    "\n",
    "    df.drop(columns=['Date_str'], inplace=True)\n",
    "    return df\n",
    "\n",
    "def augment_features(df):\n",
    "    df = df.sort_values(['StockCode', 'Date'])\n",
    "\n",
    "    # 滞后收盘价\n",
    "    df['PrevClose'] = df.groupby('StockCode')['Close'].shift(1)\n",
    "    # 日收益率\n",
    "    df['Return'] = df['Close'] / df['PrevClose'] - 1\n",
    "    # 高低价差、开收差\n",
    "    df['HighLowDiff'] = df['High'] - df['Low']\n",
    "    df['OpenCloseDiff'] = df['Open'] - df['Close']\n",
    "    # 成交量变化率\n",
    "    df['VolumePct'] = df.groupby('StockCode')['Volume'].pct_change()\n",
    "\n",
    "    # 滑动均值与标准差\n",
    "    for w in (5, 10, 20):\n",
    "        df[f'MA_{w}'] = df.groupby('StockCode')['Close'].transform(lambda x: x.rolling(w, min_periods=w).mean())\n",
    "        df[f'STD_{w}'] = df.groupby('StockCode')['Close'].transform(lambda x: x.rolling(w, min_periods=w).std())\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def scale_features(df, method='standard', scaler_path=r'C:\\Users\\27535\\Desktop\\大数据挑战赛\\model\\scaler.bin'):\n",
    "    num_cols = [\n",
    "        'Open', 'Close', 'High', 'Low',\n",
    "        'Volume', 'Turnover', 'Amplitude', 'PriceChange', 'TurnoverRate',\n",
    "        'PrevClose', 'Return', 'HighLowDiff', 'OpenCloseDiff', 'VolumePct'\n",
    "    ] + [f'MA_{w}' for w in (5, 10, 20)] + [f'STD_{w}' for w in (5, 10, 20)]\n",
    "\n",
    "    missing_cols = [col for col in num_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"以下列缺失: {missing_cols}\")\n",
    "\n",
    "    if method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise ValueError(\"method 必须是 'standard' 或 'minmax'\")\n",
    "\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"Scaler 已保存到 {scaler_path}\")\n",
    "    return df, scaler\n",
    "\n",
    "def processing_feature():\n",
    "    # 1. 读入数据并重命名\n",
    "    data = inputdata(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\data\\train.csv\")\n",
    "    data = transcolname(data, {\n",
    "        \"股票代码\": \"StockCode\", \"日期\": \"Date\", \"开盘\": \"Open\", \"收盘\": \"Close\",\n",
    "        \"最高\": \"High\", \"最低\": \"Low\", \"成交量\": \"Volume\", \"成交额\": \"Turnover\",\n",
    "        \"振幅\": \"Amplitude\", \"涨跌额\": \"PriceChange\", \"换手率\": \"TurnoverRate\",\n",
    "        \"涨跌幅\": \"PriceChangePercentage\",\n",
    "    })\n",
    "    data.drop(columns=[\"PriceChangePercentage\"], inplace=True)\n",
    "    # 2. 日期处理\n",
    "    data = trans_datetime(data)\n",
    "\n",
    "    # 3. 扩展特征\n",
    "    data = augment_features(data)\n",
    "\n",
    "    # 4. 替换 inf/-inf 为 0，再填充 NaN\n",
    "    data.replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "    data.fillna(0, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "feature = processing_feature()\n",
    "outputdata(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\temp\\feature.csv\", feature, is_index=False)\n",
    "\n",
    "# # 进行标准缩放\n",
    "# scaled_feature, scaler = scale_features(\n",
    "#     feature,\n",
    "#     method='standard',\n",
    "#     scaler_path=r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\model\\scaler.bin\"\n",
    "# )\n",
    "\n",
    "# outputdata(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\temp\\feature_scaled.csv\", scaled_feature, is_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练，样本数：616529, 批次数：9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  10%|█         | 1/10 [04:52<43:54, 292.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [1/10] loss: 7626.1672 - 耗时: 292.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  20%|██        | 2/10 [09:49<39:23, 295.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [2/10] loss: 7624.2605 - 耗时: 297.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  30%|███       | 3/10 [14:46<34:30, 295.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [3/10] loss: 7624.1462 - 耗时: 296.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  40%|████      | 4/10 [19:44<29:39, 296.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [4/10] loss: 7624.4643 - 耗时: 297.90s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  50%|█████     | 5/10 [24:40<24:42, 296.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [5/10] loss: 7624.5841 - 耗时: 296.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  60%|██████    | 6/10 [29:36<19:45, 296.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [6/10] loss: 7624.6033 - 耗时: 296.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  70%|███████   | 7/10 [34:32<14:48, 296.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [7/10] loss: 7623.0681 - 耗时: 296.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  80%|████████  | 8/10 [39:28<09:52, 296.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [8/10] loss: 7623.5405 - 耗时: 296.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度:  90%|█████████ | 9/10 [44:22<04:55, 295.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [9/10] loss: 7624.2012 - 耗时: 293.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度: 100%|██████████| 10/10 [49:14<00:00, 295.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轮次 [10/10] loss: 7624.4944 - 耗时: 292.64s\n",
      "训练完成，总耗时：2954.67 秒\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "def inputdata(path):\n",
    "    data = pd.read_csv(path, header=0, sep=\",\", encoding=\"utf-8\")\n",
    "    return data\n",
    "\n",
    "# 加载特征数据\n",
    "feature = inputdata(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\temp\\feature.csv\")\n",
    "\n",
    "# 数据处理函数\n",
    "def process_data(npdf, stp=32):\n",
    "    ret = []\n",
    "    for i in range(npdf.shape[0] - stp):\n",
    "        train_seq = npdf[i : i + stp]\n",
    "        train_label = npdf[i + stp]\n",
    "        train_seq = torch.FloatTensor(train_seq)\n",
    "        train_label = torch.FloatTensor(train_label).view(-1)\n",
    "        ret.append((train_seq, train_label))\n",
    "    return ret\n",
    "\n",
    "# 准备数据\n",
    "column_names = feature.columns.tolist()\n",
    "stockcodes = feature[\"StockCode\"].drop_duplicates().tolist()\n",
    "\n",
    "train_data = []\n",
    "for stockcode in stockcodes:\n",
    "    stock_data = feature[feature[\"StockCode\"] == stockcode]\n",
    "    max_date = stock_data[\"Date\"].max()\n",
    "    min_date = stock_data[\"Date\"].min()\n",
    "    stock_data = stock_data.values\n",
    "    if len(stock_data) < 32:\n",
    "        continue\n",
    "    train_data += process_data(stock_data, stp=32)\n",
    "\n",
    "input_size = len(column_names)\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "e_layers = 2\n",
    "dropout = 0.2\n",
    "output_size = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_size, d_model, n_heads, e_layers, output_size, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.input_embedding = nn.Linear(input_size, d_model)\n",
    "        self.embedding_ln    = nn.LayerNorm(d_model)\n",
    "        self.positional_encoding = self.create_positional_encoding(seq_len=32, d_model=d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=e_layers) \n",
    "        self.fc = nn.Linear(d_model, output_size)\n",
    "\n",
    "    def create_positional_encoding(self, seq_len, d_model):\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        return pe.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 形状：(batch_size, seq_len, input_size)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        x = self.input_embedding(x)      # (B, L, d_model)\n",
    "        x = self.embedding_ln(x)\n",
    "        pe = self.positional_encoding[:seq_len, :].unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        x = x + pe  # 添加位置编码\n",
    "        x = self.transformer_encoder(x)  # 使用 transformer_encoder\n",
    "        out = self.fc(x[:, -1, :])  # 取最后一个时间步：(batch_size, output_size)\n",
    "        return out\n",
    "\n",
    "def custom_loss(outputs, targets, f1_max_weight=0.2, spearman_max_weight=0.3, f1_min_weight=0.2, spearman_min_weight=0.3, k_ratio=0.1):\n",
    "    batch_size = targets.size(0)\n",
    "    k = max(1, int(batch_size * k_ratio))  # 最大/最小回报的样本数（例如批次的 10%）\n",
    "\n",
    "    # 重塑 outputs 和 targets\n",
    "    outputs = outputs.view(-1)  # (batch_size,)\n",
    "    targets = targets.view(-1)  # (batch_size,)\n",
    "\n",
    "    # 按回报值对 targets 排序，识别最大和最小回报\n",
    "    _, indices = torch.sort(targets, descending=True)\n",
    "    max_indices = indices[:k]  # 前 k 个样本（最大回报）\n",
    "    min_indices = indices[-k:]  # 后 k 个样本（最小回报）\n",
    "\n",
    "    # 辅助函数：计算平滑的 F1 分数\n",
    "    def compute_f1(pred, true):\n",
    "        # 使用 sigmoid 平滑二值化\n",
    "        pred_prob = torch.sigmoid(pred)  # 将预测值映射到 (0,1)\n",
    "        true_binary = (true > 0).float()  # 真实值仍使用硬二值化\n",
    "        true_positives = (pred_prob * true_binary).sum()\n",
    "        predicted_positives = pred_prob.sum()\n",
    "        actual_positives = true_binary.sum()\n",
    "        precision = true_positives / (predicted_positives + 1e-8)\n",
    "        recall = true_positives / (actual_positives + 1e-8)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        return f1\n",
    "\n",
    "    # 辅助函数：计算斯皮尔曼相关系数的可微近似\n",
    "    def compute_spearman(pred, true):\n",
    "        if len(pred) <= 1:\n",
    "            return torch.tensor(0.0, device=pred.device, requires_grad=True)\n",
    "\n",
    "        # 使用简单的相关系数近似，避免复杂的排名操作\n",
    "        pred_norm = pred - pred.mean()\n",
    "        true_norm = true - true.mean()\n",
    "        cov = (pred_norm * true_norm).sum()\n",
    "        pred_std = torch.sqrt((pred_norm ** 2).sum() + 1e-8)\n",
    "        true_std = torch.sqrt((true_norm ** 2).sum() + 1e-8)\n",
    "        pearson_corr = cov / (pred_std * true_std + 1e-8)\n",
    "        return pearson_corr  # 使用皮尔逊相关系数作为斯皮尔曼的近似\n",
    "\n",
    "    # 计算最大回报的 F1 和相关系数\n",
    "    f1_max = compute_f1(outputs[max_indices], targets[max_indices])\n",
    "    spearman_max = compute_spearman(outputs[max_indices], targets[max_indices])\n",
    "\n",
    "    # 计算最小回报的 F1 和相关系数\n",
    "    f1_min = compute_f1(outputs[min_indices], targets[min_indices])\n",
    "    spearman_min = compute_spearman(outputs[min_indices], targets[min_indices])\n",
    "\n",
    "    # 组合损失\n",
    "    loss = (\n",
    "        f1_max_weight * (1 - f1_max) +\n",
    "        spearman_max_weight * (1 - spearman_max) +\n",
    "        f1_min_weight * (1 - f1_min) +\n",
    "        spearman_min_weight * (1 - spearman_min)\n",
    "    )\n",
    "    return 1/loss\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "def train_model(train_data, i, num_epochs=10 ):\n",
    "    if len(train_data) == 0:\n",
    "        return Transformer(input_size, d_model, n_heads, e_layers, output_size, dropout).to(device)\n",
    "\n",
    "    train_data = [(x.to(device), y.to(device)) for x, y in train_data]\n",
    "\n",
    "    X_train_tensor = torch.stack([x for x, _ in train_data])\n",
    "    y_train_tensor = torch.stack([y[i] for _, y in train_data])\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = Transformer(\n",
    "        input_size=input_size,\n",
    "        d_model=d_model,\n",
    "        n_heads=n_heads,\n",
    "        e_layers=e_layers,\n",
    "        output_size=output_size,\n",
    "        dropout=dropout\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)\n",
    "\n",
    "    print(f\"开始训练，样本数：{len(train_dataset)}, 批次数：{len(train_loader)}\")\n",
    "    total_start = time.time()\n",
    "    criterion = nn.MSELoss()\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"训练进度\"):\n",
    "        epoch_start = time.time()\n",
    "        tot_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "            tot_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"轮次 [{epoch + 1}/{num_epochs}] loss: {tot_loss / len(train_loader):.4f} - 耗时: {epoch_time:.2f}s\")\n",
    "\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"训练完成，总耗时：{total_time:.2f} 秒\")\n",
    "    return model\n",
    "\n",
    "# 训练模型以预测\n",
    "colname2index = {x: i for i, x in enumerate(column_names)}\n",
    "model_i = train_model(train_data, colname2index[\"Close\"] + 2, num_epochs=10 )\n",
    "\n",
    "# 保存模型\n",
    "model_name = r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\model\\model_Close.bin\"\n",
    "pickle.dump(model_i, open(model_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测完毕，结果保存在 output/result_transformer.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import joblib\n",
    "\n",
    "pred_len = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. 与训练时完全一致的：重命名、时间拆分、特征扩增、缩放\n",
    "def inputdata(path):\n",
    "    return pd.read_csv(path, header=0, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "def transcolname(df, mapping):\n",
    "    return df.rename(columns=mapping)\n",
    "\n",
    "def trans_datetime(df):\n",
    "    df = df.copy()\n",
    "    df[\"Date_str\"] = df[\"Date\"]\n",
    "    dt = pd.to_datetime(df[\"Date_str\"], format=\"%Y-%m-%d\")\n",
    "    df[\"year\"]    = dt.dt.year\n",
    "    df[\"month\"]   = dt.dt.month\n",
    "    df[\"day\"]     = dt.dt.day\n",
    "    df[\"weekday\"] = dt.dt.weekday\n",
    "    unique_dates = dt.dt.strftime(\"%Y-%m-%d\").sort_values().unique()\n",
    "    date_map = {d: i+1 for i, d in enumerate(unique_dates)}\n",
    "    df[\"Date\"] = dt.dt.strftime(\"%Y-%m-%d\").map(date_map)\n",
    "    df.drop(columns=[\"Date_str\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "def augment_features(df):\n",
    "    df = df.sort_values([\"StockCode\",\"Date\"]).reset_index(drop=True)\n",
    "    df[\"PrevClose\"]      = df.groupby(\"StockCode\")[\"Close\"].shift(1)\n",
    "    df[\"Return\"]         = df[\"Close\"] / df[\"PrevClose\"] - 1\n",
    "    df[\"HighLowDiff\"]    = df[\"High\"] - df[\"Low\"]\n",
    "    df[\"OpenCloseDiff\"]  = df[\"Open\"] - df[\"Close\"]\n",
    "    df[\"VolumePct\"]      = df.groupby(\"StockCode\")[\"Volume\"].pct_change()\n",
    "    for w in (5,10,20):\n",
    "        df[f\"MA_{w}\"]  = df.groupby(\"StockCode\")[\"Close\"] \\\n",
    "                            .transform(lambda x: x.rolling(w,min_periods=1).mean())\n",
    "        df[f\"STD_{w}\"] = df.groupby(\"StockCode\")[\"Close\"] \\\n",
    "                            .transform(lambda x: x.rolling(w,min_periods=1).std())\n",
    "    return df\n",
    "\n",
    "def scale_features(df):\n",
    "    # 与训练时完全相同的数值列顺序\n",
    "    num_cols = [\n",
    "        \"Open\",\"Close\",\"High\",\"Low\",\n",
    "        \"Volume\",\"Turnover\",\"Amplitude\",\"PriceChange\",\"TurnoverRate\",\n",
    "        \"PrevClose\",\"Return\",\"HighLowDiff\",\"OpenCloseDiff\",\"VolumePct\"\n",
    "    ] + [f\"MA_{w}\" for w in (5,10,20)] + [f\"STD_{w}\" for w in (5,10,20)]\n",
    "\n",
    "    return df\n",
    "\n",
    "# 2. 载入训练时保存的 scaler 与模型\n",
    "# scaler = joblib.load(open(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\model\\scaler.bin\",\"rb\"))\n",
    "model = pickle.load(open(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\model\\model_Close.bin\",\"rb\"))\n",
    "model.to(device).eval()\n",
    "\n",
    "# 3. 测试数据处理函数\n",
    "def processing_feature_test(test_csv):\n",
    "    mapping = {\n",
    "        \"股票代码\":\"StockCode\",\"日期\":\"Date\",\"开盘\":\"Open\",\"收盘\":\"Close\",\n",
    "        \"最高\":\"High\",\"最低\":\"Low\",\"成交量\":\"Volume\",\"成交额\":\"Turnover\",\n",
    "        \"振幅\":\"Amplitude\",\"涨跌额\":\"PriceChange\",\"换手率\":\"TurnoverRate\",\n",
    "        \"涨跌幅\":\"PriceChangePercentage\"\n",
    "    }\n",
    "    df = inputdata(test_csv)\n",
    "    df = transcolname(df, mapping)\n",
    "    df = trans_datetime(df)\n",
    "    df = augment_features(df)\n",
    "\n",
    "    # ==== 清除 inf 和 NaN，必须在缩放前 ====\n",
    "    df.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    df = scale_features(df)\n",
    "\n",
    "    # 只保留最后 pred_len 天\n",
    "    max_date = df[\"Date\"].max()\n",
    "    df = df[df[\"Date\"] > max_date - pred_len]\n",
    "    return df\n",
    "\n",
    "\n",
    "# 4. 加载并处理 test.csv\n",
    "test_df = processing_feature_test(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\data\\test.csv\")\n",
    "feature_cols = [c for c in test_df.columns if c != \"Date\"]\n",
    "\n",
    "# 5. 按股票逐个预测\n",
    "results = []\n",
    "for sc in test_df[\"StockCode\"].unique():\n",
    "    sub = test_df[test_df[\"StockCode\"]==sc].copy()\n",
    "    if len(sub) < pred_len:\n",
    "        continue  # 数据不够\n",
    "    seq = sub[feature_cols].values[-pred_len:]          # (32, feat_dim)\n",
    "    inp = torch.tensor(seq, dtype=torch.float32)       \\\n",
    "               .unsqueeze(0).to(device)                # (1,32,feat_dim)\n",
    "    with torch.no_grad():\n",
    "        pred = model(inp)                              # (1,1)\n",
    "    pred = pred.cpu().item()\n",
    "    # 找到最后一天的真实收盘价\n",
    "    last_close = sub[sub[\"Date\"]==sub[\"Date\"].max()][\"Close\"].values[0]\n",
    "    pct_change = (pred - last_close) / last_close * 100\n",
    "    results.append((sc, pct_change))\n",
    "\n",
    "# 6. 取涨幅最大/最小10只\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "top10_up   = [r[0] for r in results[:10]]\n",
    "top10_down = [r[0] for r in results[-10:]]\n",
    "\n",
    "# 7. 保存\n",
    "out = pd.DataFrame({\n",
    "    \"涨幅最大股票代码\": top10_up,\n",
    "    \"涨幅最小股票代码\": top10_down\n",
    "})\n",
    "out.to_csv(r\"C:\\Users\\27535\\Desktop\\大数据挑战赛\\output\\result_transformer.csv\",\n",
    "           index=False, encoding=\"utf-8\")\n",
    "print(\"预测完毕，结果保存在 output/result_transformer.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
